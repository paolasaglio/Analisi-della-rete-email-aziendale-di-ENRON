---
title: "Oltre le Parole: Un'Analisi delle Email di Enron"
author: "Paola Sagliocca"
output:
  xaringan::moon_reader:
    self_contained: true
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
library(xaringanthemer)

style_mono_accent(
  base_color = "#1e1e2f",
  text_color = "#ffffff",
  #accent_color = "#f72585",
  background_color = "#16161a")


knitr::opts_chunk$set(echo = TRUE)

#install.packages(c("data.table", "igraph", "stringr", "lubridate", "readr", 
#                  "ggplot2", "tidygraph", "ggraph", "tm", "tidytext", "wordcloud", "textdata"))
library(data.table)
library(igraph)
library(stringr)
library(lubridate)
library(readr)
library(ggplot2)
library(tidygraph)
library(ggraph)
library(tm)
library(tidytext)
library(wordcloud)
library(textdata)
```




```{r pressure, echo=FALSE}

library(xaringanthemer)

style_mono_accent(
  base_color = "#1e1e2f",
  text_color = "#ffffff",
  #accent_color = "#f72585",
  background_color = "#16161a",

)


knitr::opts_chunk$set(echo = TRUE)

#install.packages(c("data.table", "igraph", "stringr", "lubridate", "readr", 
#                  "ggplot2", "tidygraph", "ggraph", "tm", "tidytext", "wordcloud", "textdata"))
library(data.table)
library(igraph)
library(stringr)
library(lubridate)
library(readr)
library(ggplot2)
library(tidygraph)
library(ggraph)
library(tm)
library(tidytext)
library(wordcloud)
library(textdata)

```

 



## Pulizia del dataset
```{r}
library(data.table)
library(stringr)
library(fasttime)
library(lubridate)

# 1. Caricamento dati
emails_raw <- fread("emails.csv")
emails_raw[, email_id := .I]

# 2. Estrazione header e corpo
estrai_headers_e_corpo <- function(messages) {
  from <- str_match(messages, "(?i)From: (.+?)\\r?\\n")[,2]
  to <- str_match(messages, "(?i)To: (.+?)\\r?\\n")[,2]
  date_match <- str_match(messages, "(?i)Date:\\s*(.+?)(\\r?\\n[ \\t].+)?\\r?\\n")
  date <- paste0(date_match[,2], ifelse(is.na(date_match[,3]), "", date_match[,3]))
  subject <- str_match(messages, "(?i)Subject: (.+?)\\r?\\n")[,2]
  corpo <- str_split_fixed(messages, "\\r?\\n\\r?\\n", 2)[,2]
  data.table(from, to, date, subject, body = corpo)
}

parsed_emails <- cbind(
  email_id = emails_raw$email_id,
  estrai_headers_e_corpo(emails_raw$message),
  file = emails_raw$file
)

# 3. Pulizia preliminare
parsed_emails <- parsed_emails[!is.na(from) & !is.na(to)]
parsed_emails[, `:=`(
  from = str_trim(tolower(from)),
  to = str_trim(tolower(to))
)]

# 4. Parsing date e filtro temporale PRIMA dello split
parsed_emails[, date_clean := str_remove_all(date, "\\s*\\([^\\)]+\\)")]
parsed_emails[, date_parsed := fastPOSIXct(date_clean, tz = "UTC")]

# Parsing alternativo se necessario
if (anyNA(parsed_emails$date_parsed)) {
  parsed_emails[is.na(date_parsed), date_parsed := parse_date_time(
    date_clean, 
    orders = c(
      "a, d b Y H:M:S z",
      "d b Y H:M:S z",
      "Y/m/d H:M:S z",
      "Y-m-d H:M:S z",
      "a d b Y H:M:S",
      "d b Y H:M:S"
    ),
    tz = "UTC"
  )]
}

# Filtro per date tra 1998 e 2004
parsed_emails <- parsed_emails[!is.na(date_parsed) & year(date_parsed) >= 1998 & year(date_parsed) <= 2004]

# 5. Conteggio pre-split
non_split_count <- nrow(parsed_emails)

# 6. Split destinatari multipli
parsed_emails <- parsed_emails[, .(
  to = unlist(str_split(to, "\\s*[,;]\\s*"))
), by = .(email_id, from, date, subject, body, file, date_parsed)]

parsed_emails <- parsed_emails[to != ""]

# 7. Estrai anno e mese
parsed_emails[, `:=`(
  year = year(date_parsed),
  month = month(date_parsed)
)]




# 9. Conteggio post-split
valid_count <- nrow(final_emails)

# 10. Report finale
cat("Email totali valide nel range 1998-2004 (senza split):", non_split_count, "\n")
cat("Email totali valide nel range 1998-2004 (dopo split):", valid_count, "\n")
cat("Distribuzione per anno:\n")
print(table(final_emails$year))

# 11. (Opzionale) Salva su file
fwrite(final_emails, "parsed_emails_1998_2004.csv")


#Nb: prima dello split --> Ogni riga = 1 email inviata, anche se ha più destinatari (Se A invia una sola email a 3 persone, è 1 riga, 1 email.)
# dopo lo split --> Ogni riga = una mail ogni singolo destinatario (Se A ha inviato una sola email a 3 persone, diventano 3 righe )
```
#ANALISI GENERALE DELLA RETE DELLE MAIL
```{r}
library(igraph)
library(data.table)


edges <- final_emails[, .(from, to)]


# Costruiamo il grafo: oriented (directed) graph
g <- graph_from_data_frame(edges, directed = TRUE)

# Possiamo anche assegnare il peso (quante email da uno stesso mittente a uno stesso destinatario)
edges_weighted <- final_emails[, .N, by = .(from, to)]
g_weighted <- graph_from_data_frame(edges_weighted, directed = TRUE)

# Visualizzazione base del grafo pesato
# Funzione per convertire esadecimale in RGB valori da 0 a 1
hex_to_rgb <- function(hex) {
  rgb <- col2rgb(hex) / 255
  return(rgb)
}

# Colori scelti
node_color <- "#0083C6"  # Blu per i nodi
green_rgb <- hex_to_rgb("#C00000")  # Verde per archi

# Verde con trasparenza per gli archi
edge_col <- rgb(green_rgb[1], green_rgb[2], green_rgb[3], alpha = 0.25)

# Impostiamo sfondo 
par(bg = "#262626")

# Plot
plot(g_weighted, 
     vertex.label = NA, 
     vertex.size = 3, 
     vertex.color = node_color,
     edge.color = edge_col, 
     edge.arrow.size = 0.2)


```
# CREA GRAFO DELLA RETE ANIUMATO IN BASE ALL'ENTRATA E USCITA DEI DIPENDENTI ALL'INTERNO DELLA RETE AZIENDALE ENRON
```{r} 
library(data.table)
library(dplyr)
library(igraph)
library(tidygraph)
library(ggraph)
library(gganimate)
library(lubridate)
library(stringr)

# --- Step 0: dati di partenza ---
# final_emails deve avere almeno: from, to, date_parsed (Date o POSIXct)

# --- Step 1: Filtra email interne @enron.com ---
emails <- final_emails[
  str_detect(from, "@enron.com$") & str_detect(to, "@enron.com$")
]

# --- Step 2: Estrai anno-mese ---
emails[, year_month := format(date_parsed, "%Y-%m")]

# --- Step 3: Crea dataframe archi per ogni mese ---
edges <- emails[, .(from, to, year_month)]

# --- Step 4: Calcola attività utenti (primo e ultimo mese) ---
activity_long <- melt(emails[, .(from, to, year_month)], measure.vars = c("from", "to"))
activity <- activity_long[, .(year_month = unique(year_month)), by = .(user = value)]
activity[, `:=`(
  first_seen = min(year_month),
  last_seen = max(year_month)
), by = user]

# --- Step 5: Tutti i mesi ordinati ---
all_months <- sort(unique(edges$year_month))

# --- Step 6: Per ogni mese crea grafo snapshot con nodi attivi ---
graph_snapshots <- list()
nodes_list <- list()
edges_list <- list()

for (m in all_months) {
  # Utenti attivi nel mese m (che hanno first_seen <= m <= last_seen)
  active_users <- activity[first_seen <= m & last_seen >= m, unique(user)]
  
  # Archi del mese, con nodi attivi
  monthly_edges <- edges[year_month == m & from %in% active_users & to %in% active_users]
  
  # Nodi: tutti gli utenti attivi, con flag active = TRUE se almeno un arco li coinvolge
  nodes <- data.table(name = active_users)
  nodes[, month := m]
  # Flag attivo = TRUE se l'utente ha almeno un arco in questo mese
  active_in_month <- unique(c(monthly_edges$from, monthly_edges$to))
  nodes[, active := name %in% active_in_month]
  
  # Salvo nodi ed archi
  nodes_list[[m]] <- nodes
  edges_list[[m]] <- monthly_edges[, .(from, to, month = m)]
}

# --- Step 7: Unisci tutti i nodi e archi in due data.table ---
all_nodes <- rbindlist(nodes_list)
all_edges <- rbindlist(edges_list)

# --- Step 8: Per evitare duplicati nodi per grafo, crea ID univoci per nodo + mese ---
all_nodes[, node_id := paste0(name, "_", month)]
all_edges[, from_id := paste0(from, "_", month)]
all_edges[, to_id := paste0(to, "_", month)]

# Step 9 corretto
all_nodes_unique <- all_nodes[, .(active = max(active) > 0), by = .(node_id, name, month)]


# --- Step 10: Crea grafo igraph con nodi e archi per tutti i mesi ---
g <- graph_from_data_frame(
  d = all_edges[, .(from = from_id, to = to_id)],
  vertices = all_nodes_unique[, .(name = node_id, active, month)],
  directed = TRUE
)

# --- Step 11: Visualizza animazione con ggraph e gganimate ---
p <- ggraph(g, layout = "fr") +
  geom_edge_link(alpha = 0.2, edge_colour = "#C00000") +
  geom_node_point(aes(color = active), size = 3) +
  scale_color_manual(values = c("TRUE" = "#0083C6", "FALSE" = "gray")) +
  theme_void() +
  labs(title = 'Mese: {closest_state}') +
  transition_states(month, transition_length = 2, state_length = 1, wrap = FALSE) +
  ease_aes('linear')

animate(p, fps = 5, width = 800, height = 600)


# Visualizza l'animazione (apparirà nel Viewer di RStudio)
print(anim)
anim_save("grafo_animato_enron.gif", animation = anim)
```


# STATISTICHE DI BASE DEL GRAFO E COMPONENTE CONNESSA PIù GRANDE
##Componenti connesse
##Percentuale e grafo della componente connessa più grande
##(assortatività)
##(reciprocità)
```{r}
# --- 1. Statistiche globali sul grafo completo ---

num_nodes <- vcount(g_weighted) # numero di nodi nel grafo pesato, cioè numero di indirizzi mail contenuti nei campi from e to
# 45474 idirizzi
num_edges <- ecount(g_weighted)

cat("Nodi totali:", num_nodes, "\n")
cat("Archi totali:", num_edges, "\n")


# Componenti connesse (weak)
comp <- components(g_weighted, mode = "weak")
cat("Numero componenti connesse:", comp$no, "\n")

# Distribuzione delle componenti
component_distribution <- table(comp$csize)
print(component_distribution)

# Percentuale di nodi nella componente principale
main_comp_size <- max(comp$csize)
cat("Percentuale nella componente principale:", round(100 * main_comp_size / num_nodes, 2), "%\n")


#Abbiamo:
# - 30 componenti di dimensione 1 → Questi sono nodi isolati (indirizzi email che non hanno connessioni bidirezionali o che sono totalmente separati dal resto).
# - 897 componenti di dimensione 2 → Piccoli gruppi di due nodi che si sono scambiati almeno una email tra loro, ma sono scollegati dal resto della rete.
# - 1 componente di dimensione 41.816 → Una “giant component”: un enorme sotto-grafo con 41.816 nodi, tutti debolmente connessi. Questo è il cuore del network, dove avviene la maggior parte della comunicazione.

#Considerazioni: La mia rete di email è molto frammentata, ma ha anche una grande componente principale, che rappresenta il nucleo connesso delle comunicazioni. Gli altri piccoli gruppu o nodi isolati possono essere comunicazioni sporadiche fuori dal network o utenti marginali.


#D'ora in poi spesso useremo la componente più grande e non tutto il grafo.
# 2. Estrai la componente principale
# Nodi della componente principale
main_nodes <- V(g_weighted)[comp$membership == which.max(comp$csize)]



# Funzione per convertire HEX in RGB (scala 0-1)
hex_to_rgb <- function(hex) {
  rgb <- col2rgb(hex) / 255
  return(rgb)
}
library(igraph)

# Colori
color_main_nodes <- "#FFA500"  # Arancione brillante
color_other_nodes <- "#555555" # Grigio scuro
edge_main <- rgb(1, 0.6, 0, alpha = 0.3)  # Arancione trasparente
edge_other <- rgb(0.7, 0.7, 0.7, alpha = 0.05)  # Grigio chiaro trasparente

# Crea vettore colori per i nodi
node_colors <- ifelse(V(g_weighted) %in% main_nodes, color_main_nodes, color_other_nodes)

# Crea vettore colori per gli archi
edge_colors <- rep(edge_other, ecount(g_weighted))
main_node_ids <- as_ids(main_nodes)
E(g_weighted)$in_main <- (as_ids(head_of(g_weighted, E(g_weighted))) %in% main_node_ids) &
                         (as_ids(tail_of(g_weighted, E(g_weighted))) %in% main_node_ids)
edge_colors[E(g_weighted)$in_main] <- edge_main

# Layout fisso per coerenza
set.seed(123)
layout_fixed <- layout_with_fr(g_weighted)

# Sfondo scuro
par(bg = "#262626")

# Plot
plot(g_weighted,
     layout = layout_fixed,
     vertex.label = NA,
     vertex.size = 2,
     vertex.color = node_colors,
     edge.color = edge_colors,
     edge.arrow.size = 0.15,
    )


# Sottografo principale
g_main <- induced_subgraph(g_weighted, vids = main_nodes)

# Info
cat("Nodi nella componente principale:", vcount(g_main), "\n")
cat("Archi nella componente principale:", ecount(g_main), "\n")





# Assortatività per grado (degree assortativity)
# Misura se i nodi con grado simile tendono a connettersi tra loro
assortativity_degree <- assortativity_degree(g_weighted, directed = TRUE)
cat("Assortatività per grado:", round(assortativity_degree, 4), "\n")

# Assortatività per grado della componente principale
assortativity_degree_main <- assortativity_degree(g_main, directed = TRUE)
cat("Assortatività per grado (componente principale):", round(assortativity_degree_main, 4), "\n")

# Interpretazione dei valori:
# > 0: assortatività positiva (nodi simili si connettono)
# < 0: disassortatività (nodi diversi si connettono)
# = 0: connessioni casuali




# Reciprocità del grafo
# --- 3. Reciprocità globale ---

# Sul grafo completo
recip_total <- reciprocity(g_weighted, mode = "default")  # default = reciprocity based on dyads
cat("Reciprocità globale (grafo completo):", round(recip_total, 4), "\n")

# Sulla componente principale
recip_main <- reciprocity(g_main, mode = "default")
cat("Reciprocità (componente principale):", round(recip_main, 4), "\n")



```



# CALCOLA METRICHE GLOBALI PER OGNI GRAFO MENSILE
```{r}
# CALCOLA METRICHE GLOBALI PER OGNI GRAFO MENSILE
library(igraph)
library(data.table)
library(lubridate)

# 1. Crea lista di mesi
mesi_analisi <- seq(ymd("2000-01-01"), ymd("2002-01-01"), by = "1 month")

# 2. Funzione per calcolare metriche di rete
calcola_metriche_rete <- function(data_mese) {
  if (nrow(data_mese) == 0) return(NULL)
  
  edges <- data_mese[, .N, by = .(from, to)]
  g <- graph_from_data_frame(edges, directed = TRUE)
  
  comps <- components(g, mode = "weak")
  giant_comp <- which.max(comps$csize)
  giant_nodes <- V(g)[comps$membership == giant_comp]
  g_giant <- induced_subgraph(g, vids = giant_nodes)
  
  list(
    nodi = vcount(g),
    archi = ecount(g),
    componenti = comps$no,
    dimensione_gigante = max(comps$csize),
    densità = edge_density(g),
    clustering_medio = transitivity(g, type = "average", isolates = "zero")
  )
}

# 3. Calcolo per ogni mese
metriche_mensili <- rbindlist(lapply(mesi_analisi, function(mese) {
  inizio <- floor_date(mese, "month")
  fine <- ceiling_date(mese, "month")
  dati_mese <- final_emails[date_parsed >= inizio & date_parsed < fine]
  
  metriche <- calcola_metriche_rete(dati_mese)
  if (is.null(metriche)) return(NULL)
  
  data.table(mese = inizio, metriche)
}), fill = TRUE)

metriche_mensili <- rbindlist(lapply(mesi_analisi, function(mese) {
  inizio <- floor_date(mese, "month")
  fine <- ceiling_date(mese, "month")
  dati_mese <- final_emails[date_parsed >= inizio & date_parsed < fine]
  
  metriche <- calcola_metriche_rete(dati_mese)
  if (is.null(metriche)) return(NULL)
  
  # Qui spacchettiamo la lista in colonne
  cbind(data.table(mese = inizio), as.data.table(metriche))
}), fill = TRUE)


# 4. Plot rapido (esempio: dimensione componente gigante)
ggplot(metriche_mensili, aes(x = mese, y = dimensione_gigante)) +
  geom_line(color = "lightgreen") +
  geom_vline(xintercept = as.Date("2001-10-01"), linetype = "dashed", color = "red") +
  labs(title = "Dimensione del componente gigante", y = "N. nodi", x = "Mese") +
  theme_minimal()



####


library(igraph)
library(data.table)
library(lubridate)


calcola_metriche_strutturali <- function(dati_mese) {
  if (nrow(dati_mese) == 0) return(NULL)
  
  edges <- dati_mese[, .N, by = .(from, to)]
  g <- graph_from_data_frame(edges, directed = TRUE)
  
  # Componente debole
  comps <- components(g, mode = "weak")
  if (length(comps$csize) == 0) return(NULL)
  
  gcc_nodes <- V(g)[comps$membership == which.max(comps$csize)]
  gcc <- induced_subgraph(g, vids = gcc_nodes)
  
  # Metriche
  list(
    nodi = vcount(g),
    archi = ecount(g),
    dimensione_gigante = length(gcc_nodes),
    percentuale_gcc = length(gcc_nodes) / vcount(g),
    numero_componenti = comps$no,
    diametro_gcc = if (vcount(gcc) > 1) diameter(gcc, directed = FALSE) else NA_real_,
    clustering = transitivity(g, type = "global")
  )
}


metriche_mensili <- rbindlist(lapply(mesi_analisi, function(mese) {
  inizio <- floor_date(mese, "month")
  fine <- ceiling_date(mese, "month")
  dati_mese <- final_emails[date_parsed >= inizio & date_parsed < fine]
  
  metriche <- calcola_metriche_strutturali(dati_mese)
  if (is.null(metriche)) return(NULL)
  
  cbind(data.table(mese = inizio), as.data.table(metriche))
}), fill = TRUE)


#stampa tabella con tutti i valori!!!
print(metriche_mensili)


#################################
#piccola parentesi prima e dopo crisi ottobre
metriche_mensili[, periodo := fifelse(mese < as.Date("2001-10-01"),
                                      "pre-crisi", "post-crisi")]

summary_periodi <- metriche_mensili[, .(
  media_percent_gcc     = mean(percentuale_gcc, na.rm = TRUE),
  mediana_percent_gcc   = median(percentuale_gcc, na.rm = TRUE),
  media_num_comp        = mean(numero_componenti, na.rm = TRUE),
  media_diametro_gcc    = mean(diametro_gcc, na.rm = TRUE),
  media_clustering      = mean(clustering, na.rm = TRUE),
  N_mesi                = .N
), by = periodo]

print(summary_periodi)
##################################








# Visualizzazione grafici:

library(reshape2)
library(ggplot2)


metriche_long <- melt(metriche_mensili, id.vars = "mese", 
                      measure.vars = c("percentuale_gcc", "numero_componenti", "diametro_gcc"),
                      variable.name = "metrica", value.name = "valore")
min_mese <- min(metriche_long$mese)
max_mese <- max(metriche_long$mese)

# Palette colori metriche (rosso, blu, verde)
col_metrica <- c(
  "percentuale_gcc" = "#C00000",    # rosso
  "numero_componenti" = "#0083C6",  # blu
  "diametro_gcc" = "#2D9C5C"        # verde
)

p <- ggplot(metriche_long, aes(x = mese, y = valore, color = metrica)) +
  geom_line(size = 0.8) +  # linea più sottile
  facet_wrap(~ metrica, scales = "free_y", ncol = 1) +
  geom_vline(xintercept = as.Date("2001-10-01"), linetype = "dashed", color = "#C00000") +  # rosso crisi ottobre
  geom_vline(xintercept = as.Date("2001-12-01"), linetype = "dashed", color = "#C00000") +  # rosso crisi dicembre
  scale_x_date(
    breaks = seq(min_mese, max_mese, by = "1 month"),
    labels = scales::date_format("%b %Y"),
    limits = c(min_mese, max_mese)
  ) +
  scale_color_manual(values = col_metrica) +
  labs(
    title = "Andamento Mensile delle Metriche Strutturali",
    x = "Mese",
    y = NULL
  ) +
  theme_minimal(base_family = "Helvetica") +
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444", size = 0.3),
    panel.grid.minor = element_blank(),
    strip.background = element_blank(),
    strip.text = element_text(color = "#7F7F7F", size = 13, face = "bold"),
    axis.text = element_text(color = "#7F7F7F", size = 11),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
    axis.title = element_text(color = "#7F7F7F", size = 13, face = "bold"),
    plot.title = element_text(color = "#7F7F7F", size = 18, face = "bold", margin = margin(b = 15)),
    legend.position = "none"
  )

# Salvo il grafico
ggsave("metriche_strutturali_ggsave.png", plot = p, width = 9, height = 9, dpi = 150, bg = "#262626")

```


# DISTRIBUZIONE DEL GRADO SU COMPONENTE CONNESSA E CALCOLO METRICHE DI CENTRALITA'
##in degree
## out-degree
## betweennes
## closeness
## eigenvector
## pagerank
```{r}
deg_table <- as.data.frame(table(degree(g_main, mode = "all")))
colnames(deg_table) <- c("degree", "count")
deg_table$degree <- as.numeric(as.character(deg_table$degree))

ggplot(deg_table, aes(x = degree, y = count)) +
  geom_line(color = "#C00000", size = 1) +
  scale_x_log10() +
  scale_y_log10() +
  labs(
    title = "Distribuzione del grado (log-log)",
    x = "Grado (log)",
    y = "Numero di nodi (log)"
  ) +
  theme_minimal(base_family = "sans") +
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold")
  )





##Controlla se la rete è scale free calcolando gamma:

library(igraph)
library(poweRlaw)

# Ottieni i gradi dalla rete (g_main è il grafo connesso)
deg <- degree(g_main)

# Crea oggetto power law discreto
pl <- displ$new(deg)

# Stima k_min e gamma
est <- estimate_xmin(pl)
pl$setXmin(est)

# Visualizza gamma stimato e xmin
cat("k_min stimato:", est$xmin, "\n")
cat("gamma stimato:", est$pars, "\n")


#3. Calcolo metriche di centralità e comunità su componente connessa
# Degree
V(g_main)$degree_in  <- degree(g_main, mode = "in")
V(g_main)$degree_out <- degree(g_main, mode = "out")

# Betweenness
V(g_main)$betweenness <- betweenness(g_main, directed = TRUE)

# Closeness
V(g_main)$closeness <- closeness(g_main, mode = "all")

# Eigenvector
V(g_main)$eigenvector <- eigen_centrality(g_main, directed = TRUE)$vector

# Calcola il PageRank sul grafo principale
# Dopo aver calcolato tutte le metriche compreso il pagerank
V(g_main)$pagerank <- page_rank(g_main, directed = TRUE)$vector

# Ricostruisci il data.table
centrality_dt <- data.table(
  email = names(V(g_main)),
  degree_in = V(g_main)$degree_in,
  degree_out = V(g_main)$degree_out,
  betweenness = V(g_main)$betweenness,
  closeness = V(g_main)$closeness,
  eigenvector = V(g_main)$eigenvector,
  pagerank = V(g_main)$pagerank,
  community = V(g_main)$community
)



top_degree_out <- centrality_dt[order(-degree_out)][1:10]
top_degree_out[, nome := sub("@.*", "", email)]
ggplot(top_degree_out, aes(x = reorder(nome, degree_out), y = degree_out)) +
  geom_col(fill = "#0083C6") +
  coord_flip() +
  labs(title = "Top 10 utenti per Email Inviate (Degree Out)",
       x = "Email", y = "Numero email inviate") +
  theme_minimal(base_size = 12)+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
  )


top_degree_in <- centrality_dt[order(-degree_in)][1:10]
top_degree_in[, nome := sub("@.*", "", email)]
ggplot(top_degree_in, aes(x = reorder(nome, degree_in), y = degree_in)) +
  geom_col(fill = "#2D9C5C") +
  coord_flip() +
  labs(title = "Top 10 utenti per Email Ricevute (Degree In)",
       x = "Email", y = "Numero email ricevute") +
  theme_minimal(base_size = 12)+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
)
    
top_betweenness <- centrality_dt[order(-betweenness)][1:10]
top_betweenness[, nome := sub("@.*", "", email)]
ggplot(top_betweenness, aes(x = reorder(nome, betweenness), y = betweenness)) +
  geom_col(fill = "#FFA500") +
  coord_flip() +
  labs(title = "Top 10 utenti per Betweenness Centrality",
       x = "Email", y = "Betweenness") +
  theme_minimal(base_size = 12)+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
  )



top_closeness <- centrality_dt[order(-closeness)][1:10]
top_closeness[, nome := sub("@.*", "", email)]
ggplot(top_closeness, aes(x = reorder(nome, closeness), y = closeness)) +
  geom_col(fill = "#C00000") +
  coord_flip() +
  labs(title = "Top 10 utenti per Closeness Centrality",
       x = "Email", y = "Closeness") +
  theme_minimal(base_size = 12)+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
  )


top_eigenvector <- centrality_dt[order(-eigenvector)][1:10]
top_eigenvector[, nome := sub("@.*", "", email)]
ggplot(top_eigenvector, aes(x = reorder(nome, eigenvector), y = eigenvector)) +
  geom_col(fill = "#570090") +
  coord_flip() +
  labs(title = "Top 10 utenti per Eigenvector Centrality",
       x = "Email", y = "Eigenvector") +
  theme_minimal(base_size = 12)+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
  )


top_pagerank <- centrality_dt[order(-pagerank)][1:10]
top_pagerank[, nome := sub("@.*", "", email)]
ggplot(top_pagerank, aes(x = reorder(nome, pagerank), y = pagerank)) +
  geom_col(fill = "#C60A6D") +
  coord_flip() +
  labs(title = "Top 10 utenti per PageRank",
       x = "Email", y = "PageRank") +
  theme_minimal(base_size = 12)+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
  )


```




# ATTIVITA' UTENTI CHIAVE PRIMA E DOPO LA CRISI
```{r}
# Analisi Email Enron 
library(data.table)
library(lubridate)
library(stringr)
library(ggplot2)
library(dplyr)
library(knitr)

# Mappatura indirizzo -> utente raggruppato
email_to_user <- list(
  "kenneth.lay@enron.com" = "Kenneth Lay",
  "klay@enron.com" = "Kenneth Lay",
  "jeff.skilling@enron.com" = "Jeff Skilling",
  "sara.shackleton@enron.com" = "Sara Shackleton",
  "gerald.nemec@enron.com" = "Gerald Nemec",
  "debra.perlingiere@enron.com" = "Debra Perlingiere",
  "vince.kaminski@enron.com" = "Vince Kaminski",
  "tim.belden@enron.com" = "Tim Belden",
  "greg.whalley@enron.com" = "Greg Whalley",
  "andrew.fastow@enron.com" = "Andrew Fastow"
)

# Funzione per mappare email a utente raggruppato
map_email_to_user <- function(email_vector, lookup) {
  sapply(email_vector, function(x) {
    if (x %in% names(lookup)) {
      return(lookup[[x]])
    } else {
      return(x)  # se non c'è mappatura, lascia l'email originale
    }
  })
}

# Assumendo che final_emails sia già caricato
# Mappa colonna 'from' e 'to'
final_emails[, from_user := map_email_to_user(from, email_to_user)]

# Per 'to', che può avere più indirizzi separati da virgola o punto e virgola
final_emails[, to_users := lapply(strsplit(to, "[,;]"), function(addr_vec) {
  trimmed <- str_trim(addr_vec)
  sapply(trimmed, function(addr) {
    if (addr %in% names(email_to_user)) email_to_user[[addr]] else addr
  })
})]

# Funzioni di conteggio CORRETTE
count_emails_sent <- function(emails, users) {
  dt <- emails[from_user %in% users]
  dt[, date_month := floor_date(date_parsed, "month")]
  sent_counts <- dt[, .N, by = .(from_user, date_month)]
  setnames(sent_counts, c("from_user", "N"), c("user", "N_sent"))
  return(sent_counts)
}

count_emails_received <- function(emails, users) {
  # Espandi le email ricevute per ogni destinatario
  dt <- emails[, .(to_user = unlist(to_users), date_parsed), by = seq_len(nrow(emails))]
  dt_filtered <- dt[to_user %in% users]
  dt_filtered[, date_month := floor_date(date_parsed, "month")]
  received_counts <- dt_filtered[, .N, by = .(to_user, date_month)]
  setnames(received_counts, c("to_user", "N"), c("user", "N_received"))
  return(received_counts)
}

# Lista degli utenti raggruppati
users_grouped <- unique(unlist(email_to_user))

# Calcola conteggi
sent_over_time <- count_emails_sent(final_emails, users_grouped)
received_over_time <- count_emails_received(final_emails, users_grouped)

# Crea griglia completa di tutti gli utenti e tutti i mesi
date_range <- seq(
  from = floor_date(min(final_emails$date_parsed, na.rm = TRUE), "month"),
  to = floor_date(max(final_emails$date_parsed, na.rm = TRUE), "month"),
  by = "month"
)

# Griglia completa utente x mese
full_grid <- expand.grid(
  user = users_grouped,
  date_month = date_range,
  stringsAsFactors = FALSE
)
setDT(full_grid)

# Merge con griglia completa per evitare buchi nei dati
activity_over_time <- full_grid %>%
  left_join(sent_over_time, by = c("user", "date_month")) %>%
  left_join(received_over_time, by = c("user", "date_month"))

# Converti in data.table e sostituisci NA con 0
setDT(activity_over_time)
activity_over_time[is.na(N_sent), N_sent := 0]
activity_over_time[is.na(N_received), N_received := 0]

# Ordina per utente e data
setorder(activity_over_time, user, date_month)

# Visualizza tabella
print("Tabella completa attività email:")
kable(head(activity_over_time, 20), 
      col.names = c("Utente", "Mese", "Email Inviate", "Email Ricevute"))

# Assicurati che date_month sia Date
activity_over_time[, date_month := as.Date(date_month)]

# Date importanti
bankruptcy_date <- as.Date("2001-12-01")
loss_announcement_date <- as.Date("2001-10-16")
skilling_resignation_date <- as.Date("2001-08-14")

# Definisci ordine utenti e team
user_order <- c(
  "Jeff Skilling", "Kenneth Lay", 
  "Sara Shackleton", "Gerald Nemec", "Debra Perlingiere", 
  "Vince Kaminski", 
  "Tim Belden", "Greg Whalley", 
  "Andrew Fastow"
)

# Aggiungi colonna team
activity_over_time <- activity_over_time %>%
  mutate(
    team = case_when(
      user %in% c("Jeff Skilling", "Kenneth Lay") ~ "Team Executive",
      user %in% c("Sara Shackleton", "Gerald Nemec", "Debra Perlingiere") ~ "Team Legal",
      user == "Vince Kaminski" ~ "Team Risk Management",
      user %in% c("Tim Belden", "Greg Whalley") ~ "Team Trader",
      user == "Andrew Fastow" ~ "Team Finanziario"
    ),
    user = factor(user, levels = user_order),
    team = factor(team, levels = c("Team Executive", "Team Legal", "Team Risk Management", "Team Trader", "Team Finanziario"))
  )

# Colori per team
team_colors <- c(
  "Team Executive" = "green",
  "Team Legal" = "magenta",
  "Team Risk Management" = "red",
  "Team Trader" = "deepskyblue",
  "Team Finanziario" = "yellow"
)

# FILTRO CORRETTO: mantieni solo righe con attività effettiva (sent OR received > 0)
# Questo evita di mostrare tutti i mesi dove non c'è attività
activity_filtered <- activity_over_time %>% 
  filter(N_sent > 0 | N_received > 0)

# Tema personalizzato
custom_theme <- theme_minimal(base_size = 15) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 11, color = "white"),
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    strip.background = element_rect(fill = "#262626", color = NA),
    strip.text = element_text(color = "white"),
    axis.text = element_text(color = "white"),
    axis.title = element_text(color = "white"),
    plot.title = element_text(color = "white"),
    plot.subtitle = element_text(color = "#7F7F7F"),
    legend.text = element_text(color = "white"),
    legend.title = element_text(color = "white"),
    panel.grid.major = element_line(color = "#444444", size = 0.5),
    panel.grid.minor = element_line(color = "#2c2c2c", size = 0.25)
  )

# Crea linea per dimissioni Skilling solo nel suo pannello
skilling_max_y <- max(activity_filtered[activity_filtered$user == "Jeff Skilling", "N_sent"], na.rm = TRUE)
skilling_resignation_line <- data.frame(
  user = factor("Jeff Skilling", levels = user_order),
  x = skilling_resignation_date,
  xend = skilling_resignation_date,
  y = 0,
  yend = skilling_max_y
)

# GRAFICO PRINCIPALE CORRETTO
p1 <- ggplot(activity_filtered, aes(x = date_month)) +
  # Linea grigia per email ricevute (sotto)
  geom_line(aes(y = N_received), color = "grey70", size = 0.8, alpha = 0.7) +
  # Linea colorata per email inviate (sopra)
  geom_line(aes(y = N_sent, color = team), size = 1.2) +
  geom_point(aes(y = N_sent, color = team), size = 1) +
  
  # Linee verticali per eventi importanti
  geom_vline(xintercept = bankruptcy_date, linetype = "dashed", color = "red", size = 1) +
  geom_vline(xintercept = loss_announcement_date, linetype = "dashed", color = "red", size = 1) +
  
  # Linea verde per dimissioni Skilling solo nel suo pannello
  geom_segment(data = skilling_resignation_line,
               aes(x = x, xend = xend, y = y, yend = yend),
               linetype = "dashed", 
               color = "green",
               size = 1,
               inherit.aes = FALSE) +
  
  # Facet per ogni utente
  facet_wrap(~ user, scales = "free_y", ncol = 3) +
  
  # Scale e colori
  scale_color_manual(values = team_colors, name = "Team") +
  scale_x_date(
    date_breaks = "6 months",
    date_labels = "%Y-%m"
  ) +
  
  # Labels
  labs(
    title = "Email inviate mensilmente dagli utenti chiave",
    subtitle = "Linee colorate: email inviate; Linee grigie: email ricevute\nLinee rosse: perdita annunciata (ott 2001) e bancarotta (dic 2001); Linea verde: dimissioni Skilling (ago 2001)",
    x = "Data", 
    y = "Numero email"
  ) +
  
  custom_theme

# Mostra il grafico
print(p1)

# Salva il grafico
ggsave(
  filename = "email_analysis_corrected.png",
  plot = p1,
  width = 16, height = 10,
  dpi = 300,
  bg = "transparent"
)

# GRAFICO AGGIUNTIVO: Solo email inviate per confronto diretto
p2 <- ggplot(activity_filtered, aes(x = date_month, y = N_sent, color = team)) +
  geom_line(size = 1.2) +
  geom_point(size = 1) +
  geom_vline(xintercept = bankruptcy_date, linetype = "dashed", color = "red") +
  geom_vline(xintercept = loss_announcement_date, linetype = "dashed", color = "red") +
  facet_wrap(~ user, scales = "free_y", ncol = 3) +
  scale_color_manual(values = team_colors, name = "Team") +
  scale_x_date(date_breaks = "6 months", date_labels = "%Y-%m") +
  labs(
    title = "Solo Email Inviate - Confronto Diretto",
    subtitle = "Linee rosse: perdita annunciata (ott 2001) e bancarotta (dic 2001)",
    x = "Data", y = "Email Inviate"
  ) +
  custom_theme

print(p2)

# Esporta anche i dati per verifica
write.csv(activity_over_time, "enron_email_activity.csv", row.names = FALSE)

# Statistiche di verifica
cat("\n=== STATISTICHE DI VERIFICA ===\n")
cat("Periodo analisi:", as.character(min(activity_over_time$date_month)), "a", as.character(max(activity_over_time$date_month)), "\n")
cat("Utenti analizzati:", length(users_grouped), "\n")
cat("Mesi totali con attività:", nrow(activity_filtered), "\n\n")

# Top 5 mesi per attività per utente
top_activity <- activity_filtered %>%
  mutate(total_activity = N_sent + N_received) %>%
  group_by(user) %>%
  top_n(3, total_activity) %>%
  arrange(user, desc(total_activity))

print("Top 3 mesi di attività per utente:")
print(kable(top_activity[,c("user", "date_month", "N_sent", "N_received", "total_activity")]))
```





#SI VALUTA IL PARADOSSO DELL'AMICIZIA:
```{r}

deg <- degree(g_main, mode = "all")
friend_deg <- sapply(V(g_main), function(v) {
  nei <- neighbors(g_main, v, mode = "all")
  if (length(nei) == 0) return(NA)
  mean(deg[nei])
})

df <- data.frame(degree = deg, friends_degree = friend_deg)

ggplot(df, aes(x = degree, y = friends_degree)) +
  geom_point(alpha = 0.3) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Paradosso dell'amicizia nella rete Enron",
       x = "Grado del nodo",
       y = "Grado medio dei vicini") +
  theme_minimal()+
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#7F7F7F"),
    panel.grid.minor = element_line(color = "#7F7F7F"),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F")
  )

sum(df$friends_degree > df$degree, na.rm = TRUE) / nrow(df)


# Calcolo grado totale
deg <- degree(g_main, mode = "all")

# Calcolo grado medio dei vicini per ciascun nodo
friend_deg <- sapply(V(g_main), function(v) {
  nei <- neighbors(g_main, v, mode = "all")
  if (length(nei) == 0) return(NA)
  mean(deg[nei])
})

# Costruisci il data frame con delta
df <- data.frame(
  email = names(V(g_main)),
  degree = deg,
  friends_degree = friend_deg
)

# Calcola la differenza: grado medio amici - grado nodo
df$delta <- df$friends_degree - df$degree #Per ogni nodo, si calcola quanto i suoi amici sono più o meno connessi rispetto a lui (delta)

#Viene tracciata la distribuzione di delta (differenza tra grado medio degli amici e grado proprio):
ggplot(df, aes(x = delta)) +
  geom_histogram(bins = 100, fill = "black", alpha = 0.7) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  labs(title = "Distribuzione della differenza: grado amici - grado proprio",
       x = "Differenza (delta)", y = "Numero di nodi") +
  theme_minimal()+
  theme(
    plot.background = element_rect(fill = "#C00000", color = NA),
    panel.background = element_rect(fill = "#C00000", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_line(color = "#444444"),
    axis.text = element_text(color = "black"),
    axis.title = element_text(color = "black"),
    plot.title = element_text(color = "black", face = "bold"),
    legend.text = element_text(color = "black"),
    legend.title = element_text(color = "black")
  )

# Rimuove gli NA (nodi senza vicini)
delta_clean <- na.omit(df$delta)

# Statistiche descrittive (min, 1 quartile, mediana, media, 3 quartile, max, deviazione standard)
summary(delta_clean)
sd(delta_clean)

#i risultati: > summ<ary(delta_clean)
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#-1294.6    28.5   119.0   234.9   303.5  1315.0 
#> sd(delta_clean)
#[1] 315.4839



#volendo capire quali sono i casi estremi che sfuggono a questa regola ovvero quelli con delta < 0:

n_total <- nrow(df)
n_anti <- nrow(antiparadosso)
percent_anti <- n_anti / n_total * 100
print(percent_anti) #risultato: il 2.02% dei nodi nella rete sfugge al paradoss. Cioè il 97.98% dei nodi conferma il paradosso dell’amico!!

antiparadosso <- df[df$delta < 0, ]
# Ordina dal più "forte" (più negativo) al meno
antiparadosso <- antiparadosso[order(antiparadosso$delta), ]
# Visualizza i primi 10
head(antiparadosso, 10)


library(ggplot2)

# Seleziona i primi 10 "antiparadossali"
top10_anti <- head(antiparadosso, 10)

# Ordina i fattori per visualizzazione corretta (dal più negativo al meno)
top10_anti$email <- factor(top10_anti$email, levels = rev(top10_anti$email))

# Crea il grafico a barre orizzontali
ggplot(top10_anti, aes(x = email, y = delta)) +
  geom_bar(stat = "identity", fill = "#7F7F7F") +
  coord_flip() +
  labs(title = "Chi sfugge al paradosso dell’amicizia?",
       subtitle = "Delta = Grado amici - Grado proprio (valori negativi)",
       x = NULL, y = "Delta") +
  theme_minimal(base_family = "sans") +
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "#7F7F7F"),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", face = "bold", size = 14),
    plot.subtitle = element_text(color = "#7F7F7F", size = 10),
    legend.position = "none"
  )


```



# ANALISI COMUNITA' 

```{r}

library(igraph)
library(data.table)
library(ggplot2)
library(viridis)
library(scales)
library(kableExtra)

# Lista anni disponibili
anni <- sort(unique(final_emails$year))

# --- 1. Funzione per calcolare le comunità usando la componente connessa più grande
calcola_comunita_anno <- function(anno, dati) {
  dati_anno <- dati[year == anno]
  edges_anno <- dati_anno[, .N, by = .(from, to)]

  if (nrow(edges_anno) == 0) return(NULL)

  g_anno <- graph_from_data_frame(edges_anno, directed = TRUE)
  comps <- components(g_anno, mode = "weak")
  giant_nodes <- V(g_anno)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g_anno, vids = giant_nodes)

  infomap_comm <- cluster_infomap(g_giant, e.weights = E(g_giant)$weight)

  list(
    year = anno,
    num_communities = length(infomap_comm),
    modularity = modularity(infomap_comm)
  )
}

# --- 2. Calcolo per tutti gli anni
result_list <- lapply(anni, function(y) calcola_comunita_anno(y, final_emails))
result_dt <- rbindlist(result_list)



# --- 4. Tabella riassuntiva (stessi dati usati nel grafico)
summary_table <- result_dt[, .(
  Anno = year,
  `N° Comunità` = num_communities,
  Modularità = round(modularity, 3),
  `Qualità Struttura` = ifelse(modularity > 0.3, "Alta", 
                               ifelse(modularity > 0.2, "Media", "Bassa"))
)]

print(summary_table)

# --- 5. Statistiche descrittive
cat("\n=== STATISTICHE DIMENSIONI BOLLE ===\n")
cat("Range numero comunità:", min(result_dt$num_communities), "-", max(result_dt$num_communities), "\n")
cat("Media numero comunità:", round(mean(result_dt$num_communities), 1), "\n")
cat("Range modularità:", round(min(result_dt$modularity), 3), "-", round(max(result_dt$modularity), 3), "\n")

# --- 6. Accesso diretto a un anno (es. 2001)
result_dt[year == 2001]





################################################################################

# ANALISI ANNUALE (non inclusa nelle slide):

################################################################################

#1. Setup e caricamento dati
library(igraph)
library(data.table)
library(ggplot2)
library(viridis)
library(scales)
library(kableExtra)

# Anni di interesse
anni_focus <- c(2000, 2001)

# VIP
vip_emails <- c(
  "jeff.skilling@enron.com", "kenneth.lay@enron.com", "k.lay@enron.com",
  "sara.shackleton@enron.com", "gerald.nemec@enron.com", "debra.perlingiere@enron.com",
  "vince.kaminski@enron.com", "tim.belden@enron.com", "greg.whalley@enron.com",
  "andrew.fastow@enron.com"
)

#2. Funzione per costruire il grafo e calcolare comunità top 5
estrai_top5_comunita <- function(anno, dati, vip_list) {
  dati_anno <- dati[year == anno]
  edges_anno <- dati_anno[, .N, by = .(from, to)]
  if (nrow(edges_anno) == 0) return(NULL)
  
  g_anno <- graph_from_data_frame(edges_anno, directed = TRUE)
  comps <- components(g_anno, mode = "weak")
  giant_nodes <- V(g_anno)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g_anno, vids = giant_nodes)
  
  if (ecount(g_giant) == 0) return(NULL)
  if (is.null(E(g_giant)$weight)) E(g_giant)$weight <- 1
  
  infomap_comm <- cluster_infomap(g_giant, e.weights = E(g_giant)$weight)
  sizes_comm <- sizes(infomap_comm)
  membership <- membership(infomap_comm)
  top5_ids <- order(sizes_comm, decreasing=TRUE)[1:5]
  
  res <- lapply(top5_ids, function(comm_id) {
    nodes_comm <- V(g_giant)[membership == comm_id]
    nodes_emails <- names(nodes_comm)
    vip_presenti <- intersect(vip_list, nodes_emails)
    
    deg <- degree(g_giant, v = nodes_comm, mode = "out")
    leader <- names(which.max(deg))
    
    data.table(
      year = anno,
      community_id = comm_id,
      size = sizes_comm[comm_id],
      vip_present = paste(vip_presenti, collapse = ", "),
      leader = leader
    )
  })
  rbindlist(res)
}


#3. Esecuzione per 2000 e 2001

top5_comunita_focus <- rbindlist(lapply(anni_focus, function(anno) estrai_top5_comunita(anno, final_emails, vip_emails)))
print(top5_comunita_focus)


#4. Metriche di centralità VIP e lead
calcola_centralita <- function(anno, dati, vip_list) {
  dati_anno <- dati[year == anno]
  edges_anno <- dati_anno[, .N, by = .(from, to)]
  g_anno <- graph_from_data_frame(edges_anno, directed = TRUE)
  comps <- components(g_anno, mode = "weak")
  giant_nodes <- V(g_anno)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g_anno, vids = giant_nodes)
  if (ecount(g_giant) == 0) return(NULL)
  if (is.null(E(g_giant)$weight)) E(g_giant)$weight <- 1
  
  vip_nodes <- intersect(vip_list, V(g_giant)$name)
  
  deg <- degree(g_giant, v = vip_nodes, mode = "out")
  betw <- betweenness(g_giant, v = vip_nodes, directed = TRUE)
  clos <- closeness(g_giant, v = vip_nodes, mode = "out")
  
  data.table(
    year = anno,
    email = vip_nodes,
    degree_out = deg,
    betweenness = betw,
    closeness = clos
  )
}

centralita_vip <- rbindlist(lapply(anni_focus, function(y) calcola_centralita(y, final_emails, vip_emails)))
print(centralita_vip)


#5. Stabilità comunità: similarità Jaccard tra membri top 5 comunità anni 2000 e 2001
jaccard_sim <- function(a, b) {
  length(intersect(a, b)) / length(union(a, b))
}

estrai_nodi_comm <- function(anno, dati) {
  dati_anno <- dati[year == anno]
  edges_anno <- dati_anno[, .N, by = .(from, to)]
  g_anno <- graph_from_data_frame(edges_anno, directed = TRUE)
  comps <- components(g_anno, mode = "weak")
  giant_nodes <- V(g_anno)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g_anno, vids = giant_nodes)
  if (ecount(g_giant) == 0) return(NULL)
  if (is.null(E(g_giant)$weight)) E(g_giant)$weight <- 1
  infomap_comm <- cluster_infomap(g_giant, e.weights = E(g_giant)$weight)
  sizes_comm <- sizes(infomap_comm)
  membership <- membership(infomap_comm)
  top5_ids <- order(sizes_comm, decreasing=TRUE)[1:5]
  lapply(top5_ids, function(comm_id) {
    V(g_giant)[membership == comm_id]$name
  })
}

nodi_2000 <- estrai_nodi_comm(2000, final_emails)
nodi_2001 <- estrai_nodi_comm(2001, final_emails)

stab_matrix <- matrix(NA, nrow=5, ncol=5)
for (i in 1:5) {
  for (j in 1:5) {
    stab_matrix[i,j] <- jaccard_sim(nodi_2000[[i]], nodi_2001[[j]])
  }
}
colnames(stab_matrix) <- paste0("2001_Comm", 1:5)
rownames(stab_matrix) <- paste0("2000_Comm", 1:5)

print(round(stab_matrix, 2))







################################################################################

#ANALISI MENSILE:

################################################################################


# 1. Librerie
library(igraph)
library(data.table)
library(ggplot2)
library(viridis)
library(scales)
library(kableExtra)
library(lubridate)
library(reshape2)

# 2. Definizione mesi target
mesi_focus <- seq(as.Date("2000-01-01"), as.Date("2002-01-01"), by = "month")

# 3. Lista VIP
vip_emails <- c(
  "jeff.skilling@enron.com", "kenneth.lay@enron.com", "k.lay@enron.com",
  "sara.shackleton@enron.com", "gerald.nemec@enron.com", "debra.perlingiere@enron.com",
  "vince.kaminski@enron.com", "tim.belden@enron.com", "greg.whalley@enron.com",
  "andrew.fastow@enron.com"
)

# 4. Funzione estrazione top 5 comunità per mese
estrai_top5_comunita_mese <- function(data_ref, dati, vip_list) {
  inizio <- floor_date(data_ref, "month")
  fine <- ceiling_date(data_ref, "month")
  
  dati_mese <- dati[date_parsed >= inizio & date_parsed < fine]
  edges <- dati_mese[, .N, by = .(from, to)]
  if (nrow(edges) == 0) return(NULL)
  
  g <- graph_from_data_frame(edges, directed = TRUE)
  comps <- components(g, mode = "weak")
  giant_nodes <- V(g)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g, vids = giant_nodes)
  
  if (ecount(g_giant) == 0) return(NULL)
  if (is.null(E(g_giant)$weight)) E(g_giant)$weight <- 1
  
  infomap_comm <- cluster_infomap(g_giant, e.weights = E(g_giant)$weight)
  sizes_comm <- sizes(infomap_comm)
  membership <- membership(infomap_comm)
  top5_ids <- head(order(sizes_comm, decreasing = TRUE), 5)
  
  res <- lapply(top5_ids, function(comm_id) {
    nodes_comm <- V(g_giant)[membership == comm_id]
    nodes_emails <- names(nodes_comm)
    vip_presenti <- intersect(vip_list, nodes_emails)
    deg <- degree(g_giant, v = nodes_comm, mode = "out")
    leader <- names(which.max(deg))
    
    data.table(
      date = inizio,
      community_id = comm_id,
      size = sizes_comm[comm_id],
      vip_present = paste(vip_presenti, collapse = ", "),
      leader = leader
    )
  })
  rbindlist(res)
}

# 5. Applicazione su tutti i mesi
top5_comunita_mensili <- rbindlist(lapply(mesi_focus, function(m) estrai_top5_comunita_mese(m, final_emails, vip_emails)))

# 6. Metriche di centralità VIP per mese
calcola_centralita_mensile <- function(data_ref, dati, vip_list) {
  inizio <- floor_date(data_ref, "month")
  fine <- ceiling_date(data_ref, "month")
  
  dati_mese <- dati[date_parsed >= inizio & date_parsed < fine]
  edges <- dati_mese[, .N, by = .(from, to)]
  if (nrow(edges) == 0) return(NULL)
  
  g <- graph_from_data_frame(edges, directed = TRUE)
  comps <- components(g, mode = "weak")
  giant_nodes <- V(g)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g, vids = giant_nodes)
  
  if (ecount(g_giant) == 0) return(NULL)
  if (is.null(E(g_giant)$weight)) E(g_giant)$weight <- 1
  
  vip_nodes <- intersect(vip_list, V(g_giant)$name)
  
  deg <- degree(g_giant, v = vip_nodes, mode = "out")
  betw <- betweenness(g_giant, v = vip_nodes, directed = TRUE)
  clos <- closeness(g_giant, v = vip_nodes, mode = "out")
  
  data.table(
    date = inizio,
    email = vip_nodes,
    degree_out = deg,
    betweenness = betw,
    closeness = clos
  )
}

centralita_vip_mensile <- rbindlist(lapply(mesi_focus, function(m) calcola_centralita_mensile(m, final_emails, vip_emails)))













#1.
#TABELLA VIP E LEADER TOP 5 COMUNITA MENSILI (2000-2002 COMPLETA)
library(knitr)
top5_table <- top5_comunita_mensili[
  , .(Leader = leader, Dimensione = size, VIP = vip_present),
  by = .(Mese = format(date, "%Y-%m"), ID_Comunita = community_id)
]
kable(top5_table, caption = "Top 5 comunità per mese", align = "l") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))


#ALTERNATIVA: TABELLA VIP E LEADER TOP 5 COMUNITA MENSILI (SOLO 2001)
library(data.table)
library(knitr)
library(kableExtra)




# 2. Tabella medie centralità dei VIP per mese
centralita_media <- centralita_vip_mensile[
  , .(
    Grado_Medio = round(mean(degree_out, na.rm = TRUE), 2),
    Betweenness_Media = round(mean(betweenness, na.rm = TRUE), 2),
    Closeness_Media = round(mean(closeness, na.rm = TRUE), 4)
  ),
  by = .(Mese = format(date, "%Y-%m"))
]

kable(centralita_media, caption = "Metriche medie di centralità dei VIP per mese") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))





# 3. GRAFICO BUBBLECHART: COME VARIA LA DIMENSIONE DELLE COMUNITA' NEI MESI - UTILE!!!
library(igraph)
library(data.table)
library(ggplot2)
library(viridis)
library(scales)
library(kableExtra)

# Funzione per calcolare comunità mese per mese
calcola_comunita_mese <- function(anno, mese, dati) {
  dati_mese <- dati[year == anno & month == mese]
  edges_mese <- dati_mese[, .N, by = .(from, to)]
  
  if (nrow(edges_mese) == 0) {
    return(data.table(
      year = anno, 
      month = mese, 
      num_communities = 0, 
      max_community_size = 0, 
      modularity = NA_real_
    ))
  }
  
  g_mese <- graph_from_data_frame(edges_mese, directed = TRUE)
  comps <- components(g_mese, mode = "weak")
  giant_nodes <- V(g_mese)[comps$membership == which.max(comps$csize)]
  g_giant <- induced_subgraph(g_mese, vids = giant_nodes)
  
  infomap_comm <- cluster_infomap(g_giant, e.weights = E(g_giant)$weight)
  
  sizes <- sizes(infomap_comm)
  max_size <- max(sizes)
  mod <- modularity(infomap_comm)
  
  data.table(
    year = anno, 
    month = mese, 
    num_communities = length(infomap_comm), 
    max_community_size = max_size, 
    modularity = mod
  )
}

# Sequenza mesi da Gen 2000 a Gen 2002
mesi_seq <- seq(as.Date("2000-01-01"), as.Date("2002-01-01"), by = "month")
mesi_dt <- data.table(
  year = year(mesi_seq),
  month = month(mesi_seq)
)

# Calcolo comunità mese per mese
result_mensile_list <- lapply(1:nrow(mesi_dt), function(i) {
  calcola_comunita_mese(mesi_dt$year[i], mesi_dt$month[i], final_emails)
})
result_mensile <- rbindlist(result_mensile_list)

# Colonna data
result_mensile[, date := as.Date(paste(year, month, "01", sep = "-"))]

# GRAFICO
p <- ggplot(result_mensile, aes(x = date, y = num_communities)) +
  geom_point(aes(size = max_community_size, fill = modularity),
             shape = 21, color = "black", alpha = 0.8) +
  geom_vline(xintercept = as.Date(c("2001-10-01", "2001-12-01")),
             color = "red", linewidth = 0.8) +  # linee rosse continue
  scale_size_area(name = "Grandezza max Comunità", max_size = 35) +
  scale_fill_gradient2(
    low = "blue", mid = "red", high = "green",
    midpoint = median(result_mensile$modularity, na.rm = TRUE),
    na.value = "grey50"
  ) +
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 months", expand = c(0.05, 0.05)) +
  scale_y_continuous(expand = expansion(mult = c(0.1, 0.1))) + 
  labs(
    title = "Comunità di email da Gen 2000 a Gen 2002",
    x = "Mese",
    y = "Numero di Comunità"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.background = element_rect(fill = "#262626", color = NA),
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#444444"),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "white"),
    axis.title = element_text(color = "white"),
    plot.title = element_text(color = "#7F7F7F", face = "bold"),
    legend.background = element_rect(fill = "#262626"),
    legend.key = element_rect(fill = "#262626"),
    legend.text = element_text(color = "#7F7F7F", size = 16),
    legend.title = element_text(color = "#7F7F7F", size = 16),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 15)
  )

print(p)

# Salva con ggsave (raccomandato)
ggsave("comunita_email_wide.png", 
       plot = p, 
       width = 19,        # Larghezza in pollici
       height = 9,        # Altezza in pollici  
       dpi = 300,         # Risoluzione alta
       bg = "#262626")    # Sfondo scuro



# Tabella riepilogativa con dimensione massima comunità
result_mensile %>%
  .[, .(
    Anno = year, 
    Mese = month, 
    Data = format(date, "%Y-%m-%d"), 
    Numero_Comunita = num_communities, 
    Grandezza_Massima = max_community_size, 
    Modularita = round(modularity, 3)
  )] %>%
  kable(caption = "Tabella riepilogativa delle comunità email per mese (dimensione massima)") %>%
  kable_styling(full_width = FALSE, position = "center")





#CENTRALITA MEDIA DEI VIP NEI MESI - UTILE!!
# Assegna il grafico a un oggetto
p <- ggplot(plot_dt, aes(x = date, y = mean, color = metrica, fill = metrica)) +
  geom_line(size = 1.2) +
  geom_ribbon(aes(ymin = mean - sd, ymax = mean + sd), alpha = 0.25, color = NA) +
  facet_wrap(~metrica, scales = "free_y") +
  scale_color_manual(values = colori) +
  scale_fill_manual(values = colori) +
  scale_x_date(
    date_labels = "%Y-%m",
    date_breaks = "2 month",
    expand = expansion(mult = c(0.01, 0.01))
  ) +
  labs(
    title = "Evoluzione mensile delle metriche medie di centralità dei VIP",
    x = "Mese",
    y = "Valore medio ± deviazione standard",
    color = "Metrica",
    fill = "Metrica"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    panel.grid.major = element_line(color = "#222222"),
    panel.grid.minor = element_blank(),
    strip.background = element_rect(fill = "#444444"),
    strip.text = element_text(color = "#7F7F7F", size = 14),
    axis.text = element_text(color = "#7F7F7F", angle = 90, hjust = 1),
    axis.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", size = 16, face = "bold"),
    legend.position = "none"
  )

# Salva in PNG (modifica il percorso e nome file a piacere)
ggsave(filename = "centralita_vip_mensili.png", plot = p, width = 12, height = 5, dpi = 300)


```




# GRAFICO Volume Email e Prezzo Azione Enron con Eventi e Analisi Pre/Post (animato + statico)
```{r}


library(dplyr)
library(tidyr)
library(ggplot2)
library(gganimate)
library(readxl)
library(scales)
library(RColorBrewer)


eventi <- data.frame(
  data = as.Date(c(
    "2000-08-23",  # Picco del titolo
    "2001-08-14",  # Dimissioni di Skilling
    "2001-10-16",  # Enron annuncia perdita
    "2001-10-22",  # Inchiesta SEC
    "2001-11-28",  # Titolo sotto $1
    "2001-12-02",  # Bancarotta
    "2002-01-01"   # Andersen accusata
  )),
  evento = c(
    "Picco titolo ($90)",
    "Dimissioni di Skilling",
    "Perdita $618M annunciata",
    "Indagine SEC",
    "Titolo sotto $1",
    "Bancarotta",
    "Accusa Andersen"
  )
)



# --- 1. Caricamento dati ---
# Carica e filtra email
email_volume_daily <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  group_by(date) %>%
  summarise(n_email = n()) %>%
  filter(date >= as.Date("2000-01-01"))

# Carica dati borsa
file_path <- file.choose() #caricare dataset "enron-historical-data-1"
stock_data <- read_excel(file_path, skip = 4) %>%
  mutate(date = as.Date(Date, format = "%m/%d/%Y")) %>%
  filter(date >= as.Date("2000-01-01")) %>%
  select(date, Close)


# Crea etichette con evento e data su righe separate (evento prima)
eventi$evento_con_data <- paste0(eventi$evento, "\n(", format(eventi$data, "%b %Y"), ")")

# Ordina 'evento_con_data' come factor per mantenere ordine nella legenda
eventi$evento_con_data <- factor(eventi$evento_con_data, levels = eventi$evento_con_data)

# Palette con 9 colori ben distinti
colori_eventi <- brewer.pal(n = 9, name = "Set1")

# --- 3. Unione e normalizzazione ---
combined <- full_join(email_volume_daily, stock_data, by = "date") %>%
  arrange(date) %>%
  filter(!is.na(n_email) & !is.na(Close))

combined <- combined %>%
  mutate(
    email_norm = (n_email - min(n_email)) / (max(n_email) - min(n_email)),
    close_norm = (Close - min(Close)) / (max(Close) - min(Close))
  )

combined_long <- combined %>%
  select(date, email_norm, close_norm) %>%
  pivot_longer(cols = c(email_norm, close_norm),
               names_to = "variabile",
               values_to = "valore") %>%
  mutate(variabile = recode(variabile,
                            "email_norm" = "Volume Email",
                            "close_norm" = "Prezzo Azione"))

# --- 4. Grafico animato con linee evento colorate e legenda ---
# Colori fissi per le due variabili
# Colori fissi per le due variabili (linee)
colori_linee <- c("Prezzo Azione" = "steelblue", "Volume Email" = "red")

# Combina palette eventi e colori linee per scale_color_manual
colori_eventi_named <- setNames(colori_eventi, levels(eventi$evento_con_data))
colori_completi <- c(colori_linee, colori_eventi_named)

p <- ggplot() +
  geom_line(data = combined_long,
            aes(x = date, y = valore, color = variabile),
            size = 1.2) +

  geom_vline(data = eventi,
             aes(xintercept = data, color = evento_con_data),
             linetype = "solid", size = 0.8, alpha = 0.9) +

  scale_color_manual(
    name = NULL,
    values = colori_completi,
    breaks = c("Prezzo Azione", "Volume Email", levels(eventi$evento_con_data)),
    labels = c("Prezzo Azione", "Volume Email", levels(eventi$evento_con_data))
  ) +

  scale_x_date(
    date_breaks = "3 months",
    date_labels = "%b %Y",
    minor_breaks = seq(min(combined$date, na.rm = TRUE), max(combined$date, na.rm = TRUE), by = "1 month")
  ) +   # ✅ QUI IL + È CORRETTO

  labs(
    title = "Evoluzione Volume Email e Prezzo Azione Enron",
    x = "Data",
    y = "Valore normalizzato (0-1)"
  ) +

  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    legend.background = element_rect(fill = "#262626", color = NA),
    legend.key = element_rect(fill = "#262626"),
    text = element_text(color = "white"),
    axis.text = element_text(color = "white"),
    legend.text = element_text(color = "white", size = 8, lineheight = 1.8),
    legend.key.height = unit(2.5, "lines"),
    legend.spacing.y = unit(0.5, "cm"),
    legend.title = element_text(color = "white"),
    plot.title = element_text(color = "white"),
    axis.title = element_text(color = "white"),
    panel.grid.major = element_line(color = "#444444", size = 0.3),
    panel.grid.minor = element_line(color = "#333333", size = 0.2)
  ) +

  transition_reveal(along = date)

# --- Salva animazione ---
animate(p, fps = 10, duration = 25, width = 1200, height = 550, renderer = gifski_renderer(loop = FALSE))
anim_save("enron_email_vs_stock_with_events.gif")




library(dplyr)

# Assicurati che 'email_volume_daily' abbia le colonne: date (Date) e n_email (numero email al giorno)
# Assicurati che 'eventi' abbia le colonne: evento (nome evento) e data (Date)

# Calcolo volume medio email nei 7 giorni prima e dopo ogni evento
risultato_eventi <- eventi %>%
  rowwise() %>%
  mutate(
    volume_pre = mean(email_volume_daily$n_email[
      email_volume_daily$date >= data - 7 & email_volume_daily$date < data
    ], na.rm = TRUE),

    volume_post = mean(email_volume_daily$n_email[
      email_volume_daily$date > data & email_volume_daily$date <= data + 7
    ], na.rm = TRUE),

    delta_assoluto = volume_post - volume_pre,

    delta_percentuale = ifelse(volume_pre > 0,
                               (volume_post - volume_pre) / volume_pre * 100,
                               NA_real_)
  ) %>%
  ungroup()

# Visualizza risultati ordinati per maggiore aumento percentuale
risultato_eventi %>%
  arrange(desc(delta_percentuale)) %>%
  select(evento, data, volume_pre, volume_post, delta_assoluto, delta_percentuale) %>%
  print(n = Inf)  # Mostra tutte le righe





library(dplyr)
library(gt)

tabella_gt <- risultato_eventi %>%
  arrange(data) %>%   # Ordine cronologico per data
  select(evento, data, volume_pre, volume_post, delta_assoluto, delta_percentuale) %>%
  gt(rowname_col = "evento") %>%

  
  tab_options(
    table.background.color = "#262626",
    table.font.color = "#7F7F7F",
    table.border.top.color = "#1A1A1A",
    table.border.bottom.color = "#1A1A1A"
  ) %>%
  
  opt_row_striping(FALSE) %>%
  
  tab_style(
    style = list(
      cell_borders(
        sides = c("bottom", "right"),
        color = "#1A1A1A",
        weight = px(1)
      )
    ),
    locations = cells_body()
  ) %>%
  
  tab_style(
    style = cell_text(color = "#7F7F7F"),
    locations = cells_column_labels(everything())
  ) %>%
  
  tab_style(
    style = cell_text(color = "#7F7F7F"),
    locations = cells_stub()
  ) %>%
  
  tab_style(
    style = cell_text(color = "#7F7F7F"),
    locations = cells_body()
  ) %>%
  
  tab_style(
    style = cell_text(color = "#C00000"),
    locations = cells_title(groups = "title")
  ) %>%
  
  tab_header(
    title = md("**Variazione volume email pre e post evento**")
  ) %>%
  
  fmt_number(columns = c(volume_pre, volume_post, delta_assoluto), decimals = 2) %>%
  fmt_number(columns = delta_percentuale, decimals = 2, pattern = "{x}%") %>%
  
  # Colora in rosso i valori negativi di delta_percentuale
  tab_style(
    style = cell_text(color = "#C00000"),
    locations = cells_body(
      columns = delta_percentuale,
      rows = delta_percentuale < 0
    )
  ) %>%
  
  # Colora in verde i valori positivi di delta_percentuale
  tab_style(
    style = cell_text(color = "#2D9C5C"),
    locations = cells_body(
      columns = delta_percentuale,
      rows = delta_percentuale > 0
    )
  )

tabella_gt

#install.packages("webshot2")
library(gt)
library(webshot2)
gtsave(tabella_gt, "tabella_variazioni.volume.png")




####################################
####################################
# Grafico statico identico a quello animato
p_static <- ggplot() +
  geom_line(data = combined_long,
            aes(x = date, y = valore, color = variabile),
            size = 1.2) +

  geom_vline(data = eventi,
             aes(xintercept = data, color = evento_con_data),
             linetype = "solid", size = 0.8, alpha = 0.9) +

  scale_color_manual(
    name = NULL,
    values = colori_completi,
    breaks = c("Prezzo Azione", "Volume Email", levels(eventi$evento_con_data)),
    labels = c("Prezzo Azione", "Volume Email", levels(eventi$evento_con_data))
  ) +

  scale_x_date(
    date_breaks = "3 months",
    date_labels = "%b %Y",
    minor_breaks = seq(min(combined$date, na.rm = TRUE),
                       max(combined$date, na.rm = TRUE),
                       by = "1 month")
  ) +

  labs(
    title = "Evoluzione Volume Email e Prezzo Azione Enron",
    x = "Data",
    y = "Valore normalizzato (0-1)"
  ) +

  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    legend.background = element_rect(fill = "#262626", color = NA),
    legend.key = element_rect(fill = "#262626"),
    text = element_text(color = "white"),
    axis.text = element_text(color = "white"),
    legend.text = element_text(color = "white", size = 8, lineheight = 1.8),
    legend.key.height = unit(2.5, "lines"),
    legend.spacing.y = unit(0.5, "cm"),
    legend.title = element_text(color = "white"),
    plot.title = element_text(color = "white"),
    axis.title = element_text(color = "white"),
    panel.grid.major = element_line(color = "#444444", size = 0.3),
    panel.grid.minor = element_line(color = "#333333", size = 0.2)
  )

# Salva come immagine PNG
ggsave("grafico_statico_enron.png", p_static, width = 12, height = 5.5, dpi = 300, bg = "transparent")

```

## CHI SONO I 10 TOP SENDERS E DESTINATARI NELLA CRISI 
```{r}

library(dplyr)
library(ggplot2)
library(tidyr)

# Calcola i top 10 mittenti nel periodo specificato
top_10_senders <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(date >= as.Date("2001-10-01") & date <= as.Date("2001-12-31")) %>%
  count(from, sort = TRUE) %>%
  slice(1:10) %>%
  arrange(desc(n)) %>%  # Ordina per numero di email
  mutate(percentage = n / sum(n) * 100,
         label = paste0(from, " (", round(percentage, 1), "%)"))

# Ordina la legenda in base alle percentuali (decrescente)
top_10_senders$label <- factor(top_10_senders$label, levels = top_10_senders$label)

# Imposta i colori manuali: verde per Jae Black, altri grigi automatici o personalizzati
custom_colors <- ifelse(grepl("jae.black@enron.com", top_10_senders$from), "darkgreen", scales::hue_pal()(10))

# Crea il grafico a torta
p <- ggplot(top_10_senders, aes(x = "", y = n, fill = label)) +
  geom_col(width = 1) +
  coord_polar("y", start = 0) +
  labs(
    title = "Top 10 Mittenti (Ott-Dic 2001)",
    y = NULL, x = NULL,
    fill = "TOP 10 mittenti ottobre-dicembre"
  ) +
  scale_fill_manual(values = custom_colors) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    legend.background = element_rect(fill = "#262626", color = NA),
    legend.text = element_text(color = "#7F7F7F"),
    legend.title = element_text(color = "#7F7F7F"),
    plot.title = element_text(color = "#7F7F7F", size = 14, face = "bold")
  )

# Salva il grafico
ggsave("grafico_torta__top_10_mittenti.png", plot = p, width = 8, height = 6, dpi = 300)
 print(p)


 
#percentuale di questi 10 top senders in relazione a tutti gli altri
# Totale email nel periodo
total_emails <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(date >= as.Date("2001-10-01") & date <= as.Date("2001-12-31")) %>%
  nrow()

# Email inviate dai top 10 mittenti
top_10_emails <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(date >= as.Date("2001-10-01") & date <= as.Date("2001-12-31")) %>%
  count(from, sort = TRUE) %>%
  slice(1:10) %>%
  summarise(total_top_10 = sum(n)) %>%
  pull(total_top_10)

# Calcolo percentuale
percentage_top_10 <- top_10_emails / total_emails * 100

# Mostra il risultato
percentage_top_10





top_recipients <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(date >= as.Date("2001-10-01") & date <= as.Date("2001-12-31")) %>%
  separate_rows(to, sep = "\\s*[,]\\s*") %>%
  count(to, sort = TRUE)

head(top_recipients, 20)

top_10_senders <- top_10_senders$from

email_by_sender <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(from %in% top_10_senders) %>%
  group_by(date, from) %>%
  summarise(n_email = n()) %>%
  ungroup()

ggplot(email_by_sender, aes(x = date, y = n_email, color = from)) +
  geom_line(size = 1) +
  labs(title = "Volume Email per Mittente (Top 10)",
       x = "Data", y = "Numero di Email") +
  theme_minimal()






library(dplyr)
library(gt)

# 1. Calcolo volume medio giornaliero a settembre e ottobre per i top 10 sender
variazione_senders <- final_emails %>%
  mutate(date = as.Date(date_parsed),
         mese = format(date, "%Y-%m"),
         giorno = date) %>%
  filter(from %in% top_10_senders,
         mese %in% c("2001-09", "2001-10")) %>%
  group_by(from, mese) %>%
  summarise(
    media_giornaliera = n() / n_distinct(giorno),
    totale = n(),
    .groups = "drop"
  ) %>%
  pivot_wider(
    names_from = mese,
    values_from = c(media_giornaliera, totale),
    values_fill = 0
  ) %>%
  mutate(
    delta_assoluto = `media_giornaliera_2001-10` - `media_giornaliera_2001-09`,
    delta_percentuale = ifelse(`media_giornaliera_2001-09` > 0,
                               (delta_assoluto / `media_giornaliera_2001-09`) * 100,
                               NA_real_)
  ) %>%
  arrange(desc(delta_percentuale))

print(variazione_senders)









# IN PIU' : QUANTE MAIL SONO INVIATE A INDIRIZZI COLLETTIVI? non troppissime come pensavo
collective_emails <- final_emails %>%
  filter(str_detect(tolower(to), "all enron")) %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(date >= as.Date("2001-10-01") & date <= as.Date("2001-12-31")) %>%
  count(date)

ggplot(collective_emails, aes(x = date, y = n)) +
  geom_line(color = "steelblue") +
  labs(title = "Email inviate a indirizzi collettivi (All Enron)",
       x = "Data", y = "Numero di email") +
  theme_minimal()

daily_totals <- final_emails %>%
  mutate(date = as.Date(date_parsed)) %>%
  filter(date >= as.Date("2001-10-01") & date <= as.Date("2001-12-31")) %>%
  count(date, name = "totale")

daily_collective <- final_emails %>%
  filter(str_detect(tolower(to), "all enron")) %>%
  mutate(date = as.Date(date_parsed)) %>%
  count(date, name = "collettive")

join_data <- left_join(daily_totals, daily_collective, by = "date") %>%
  mutate(percentuale_collettive = (collettive / totale) * 100)

ggplot(join_data, aes(x = date, y = percentuale_collettive)) +
  geom_line(color = "darkred") +
  labs(title = "% Email inviate a indirizzi collettivi",
       x = "Data", y = "Percentuale") +
  theme_minimal()

print(join_data)


summary_stats <- join_data %>%
  summarise(
    tot_email = sum(totale, na.rm = TRUE),
    tot_collettive = sum(collettive, na.rm = TRUE),
    media_percentuale = mean(percentuale_collettive, na.rm = TRUE),
    max_percentuale = max(percentuale_collettive, na.rm = TRUE),
    giorno_picco = date[which.max(percentuale_collettive)]
  )

print(summary_stats)


```




#TROVO I TOP TOPIC PER TUTTI I TOP 5 MITTENTI E DESTINATARI NEL PERIODO DI CRISI (prima e durante). 
##Obiettivo: wordcloud
##TECNICA: risultati di un modello LDA (Latent Dirichlet Allocation) per ciascun mittente, separatamente per due periodi temporali: pre-crisi e durante la crisi.
```{r}

library(dplyr)
library(tidytext)
library(topicmodels)
library(stringr)
library(readr)
library(ggplot2)
library(ggwordcloud) # serve per geom_text_wordcloud_area()

run_lda_for_person <- function(email_address, start_date, end_date, prefix) {
  emails_person <- parsed_emails %>%
    filter(
      date_parsed >= as.POSIXct(start_date) &
      date_parsed <= as.POSIXct(end_date) &
      (from == email_address | to == email_address)
    ) %>%
    mutate(email_id = row_number())
  
  email_words <- emails_person %>%
    select(email_id, body) %>%
    unnest_tokens(word, body) %>%
    anti_join(stop_words, by = "word") %>%
    filter(str_detect(word, "[a-z]"))
  
  email_dtm <- email_words %>%
    count(email_id, word) %>%
    cast_dtm(document = email_id, term = word, value = n)
  
  if (nrow(emails_person) == 0 || nrow(email_words) == 0) {
    message(paste("No emails or tokens for", email_address, "in period", start_date, "-", end_date))
    return(NULL)
  }
  
  lda_model <- LDA(email_dtm, k = 3, control = list(seed = 123))
  topics <- tidy(lda_model, matrix = "beta")
  top_terms <- topics %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    arrange(topic, -beta)
  
  # Salva csv con nome personalizzato
  file_name <- paste0("top_terms_", prefix, "_", gsub("[@.]", "_", email_address), ".csv")
  write_csv(top_terms, file_name)
  
  return(top_terms)
}





# Funzione per aggregare i termini top da tutti i mittenti per un periodo
aggregate_top_terms <- function(prefix, senders) {
  all_terms <- data.frame()
  
  for (email in senders) {
    file_name <- paste0("top_terms_", prefix, "_", gsub("[@.]", "_", email), ".csv")
    if (file.exists(file_name)) {
      terms <- read_csv(file_name, show_col_types = FALSE) %>%
        select(term, beta)
      all_terms <- bind_rows(all_terms, terms)
    }
  }
  
  all_terms_clean <- all_terms %>%
    filter(!str_detect(term, "<|>|/|@|\\[|\\]|=|\\(|\\)|\\{|\\}|\\*|\\&|%|\\$|#|\\+")) %>%
    filter(str_detect(term, "^[a-z]+$")) %>%       # solo parole alfabetiche
    filter(nchar(term) > 2)                        # 🔹 FILTRO AGGIUNTO: solo parole > 2 caratteri
  
  all_terms_agg <- all_terms_clean %>%
    group_by(term) %>%
    summarise(beta = sum(beta, na.rm = TRUE)) %>%
    arrange(desc(beta)) %>%
    slice_max(beta, n = 100)
  
  return(all_terms_agg)
}







make_wordcloud <- function(df_terms, title, color = "black") {
  ggplot(df_terms, aes(label = term, size = beta)) +
    geom_text_wordcloud(
      color = color,
      rm_outside = TRUE,
      grid_size = 5,
      family = "sans",
      shape = "square"   # <- imposta forma quadrata
    ) +
    scale_size_area(max_size = 15) +
    ggtitle(title) +
    theme_minimal(base_family = "sans") +
    theme(
      plot.background = element_rect(fill = "#262626", color = NA),
      panel.background = element_rect(fill = "#262626", color = NA),
      plot.title = element_text(color = "#7F7F7F", size = 16, face = "bold", hjust = 0.5)
    )
}



# Mittenti principali
senders <- c(
  "jae.black@enron.com",
  "no.address@enron.com",
  "darran.binns@enron.com",
  "howard.fromer@enron.com", 
  "jeff.dasovich@enron.com",
  "d..steffes@enron.com",
  "mike.grigsby@enron.com",
  "pete.davis@enron.com",
  "louise.kitchen@enron.com",
  "rod.hayslett@enron.com"
)

# Esegui LDA e salva top_terms per mittenti pre-crisi
for (email in senders) {
  run_lda_for_person(email, "2001-04-01", "2001-09-30 23:59:59", "precrisi")
}

# Esegui LDA e salva top_terms per mittenti durante crisi  
for (email in senders) {
  run_lda_for_person(email, "2001-10-01", "2001-10-31 23:59:59", "crisi")
}


###################
#PER VISUALIZZARE WORDCLOUD RIASSUNTIVO
# Aggrega e crea wordcloud pre-crisi
precrisi_terms <- aggregate_top_terms("precrisi", senders)
p1 <- make_wordcloud(precrisi_terms, 
                     "Wordcloud Top Mittenti Pre-Crisi (Aprile-Settembre)", 
                     "darkgreen")

# Aggrega e crea wordcloud durante crisi
crisi_terms <- aggregate_top_terms("crisi", senders)
p2 <- make_wordcloud(crisi_terms, 
                     "Wordcloud Top Mittenti Durante la Crisi (Ottobre-Dicembre)", 
                     "red")

# Salva le immagini
ggsave("wordcloud_precrisi.png", plot = p1, width = 12, height = 8, dpi = 300, bg = "#262626")
ggsave("wordcloud_crisi.png", plot = p2, width = 12, height = 8, dpi = 300, bg = "#262626")

# Visualizza i plot
print(p1)
print(p2)

# Salva le immagini separatamente
ggsave("wordcloud_precrisi.png", plot = p1, width = 12, height = 8, dpi = 300, bg = "#262626")
ggsave("wordcloud_crisi.png", plot = p2, width = 12, height = 8, dpi = 300, bg = "#262626")









##colora solo parole uniche


# Ottieni i termini da entrambi i periodi
precrisi_terms <- aggregate_top_terms("precrisi", senders)
crisi_terms <- aggregate_top_terms("crisi", senders)

# Termini comuni
common_terms <- intersect(precrisi_terms$term, crisi_terms$term)

# Aggiungi una colonna per il colore in ciascun data frame
precrisi_terms$color <- ifelse(precrisi_terms$term %in% common_terms, "#7F7F7F", "darkgreen")
crisi_terms$color   <- ifelse(crisi_terms$term %in% common_terms, "#7F7F7F", "red")

# Funzione per creare wordcloud quadrata
make_wordcloud <- function(data, title) {
  ggplot(data, aes(label = term, size = beta, color = color)) +
    ggwordcloud::geom_text_wordcloud(
      shape = "square",       # <-- forma quadrata
      area_corr = TRUE,
      rm_outside = TRUE,
      grid_size = 5,
      family = "sans"
    ) +
    scale_size_area(max_size = 20) +
    scale_color_identity() +
    theme_minimal(base_size = 16, base_family = "sans") +
    labs(title = title) +
    theme(
      plot.background = element_rect(fill = "#262626", color = NA),
      panel.background = element_rect(fill = "#262626", color = NA),
      plot.title = element_text(color = "#CCCCCC", size = 16, face = "bold", hjust = 0.5)
    )
}

p1 <- make_wordcloud(precrisi_terms, 
                     "Wordcloud Top Mittenti Pre-Crisi (Aprile-Settembre)")

p2 <- make_wordcloud(crisi_terms, 
                     "Wordcloud Top Mittenti Durante la Crisi (Ottobre-Dicembre)")

ggsave("wordcloud_precrisi_colorati.png", plot = p1, width = 12, height = 8, dpi = 300, bg = "#262626")
ggsave("wordcloud_crisi_colorati.png", plot = p2, width = 12, height = 8, dpi = 300, bg = "#262626")

print(p1)
print(p2)

# Parole uniche pre-crisi (colorate in verde)
cat("Parole uniche Pre-Crisi:\n")
print(precrisi_terms$term[precrisi_terms$color == "darkgreen"])

# Parole uniche durante la crisi (colorate in rosso)
cat("\nParole uniche Durante la Crisi:\n")
print(crisi_terms$term[crisi_terms$color == "red"])





# Messaggio di conferma
cat("Wordcloud salvati come:\n")
cat("- wordcloud_precrisi.png\n")
cat("- wordcloud_crisi.png\n")

cat("Parole Wordcloud Pre-Crisi (Aprile-Settembre):\n")
print(precrisi_terms)

cat("\nParole Wordcloud Durante la Crisi (Ottobre-Dicembre):\n")
print(crisi_terms)

print(precrisi_terms)  # Parole pre-crisi
print(crisi_terms)     # Parole durante la crisi


###################




# Funzione per mostrare le top parole di un mittente in un periodo
mostra_top_parole <- function(email, periodo) {
  file_name <- paste0("top_terms_", periodo, "_", gsub("[@.]", "_", email), ".csv")
  
  if (!file.exists(file_name)) {
    cat("❌ File non trovato per", email, "nel periodo", periodo, "\n")
    return(NULL)
  }
  
  terms <- read_csv(file_name, show_col_types = FALSE) %>%
    group_by(topic) %>%
    slice_max(beta, n = 10) %>%
    arrange(topic, -beta)
  
  cat(paste0("\n🔍 Top parole per ", email, " nel periodo ", periodo, ":\n"))
  print(terms)
}



```



#SONO STATI I VIP A CONTRIBUIRE ALL'AUMENTO DEL VOLUME DI MAIL ? (NO)
```{r}

library(dplyr)
library(lubridate)
library(ggplot2)
library(gt)
library(tidyr)


# Verifica presenza colonne
colonne_presenti <- colnames(final_emails)

has_cc <- "cc" %in% colonne_presenti
has_bcc <- "bcc" %in% colonne_presenti


# Lista VIP
vip_emails <- c(
  "jeff.skilling@enron.com", "kenneth.lay@enron.com", "k.lay@enron.com",
  "sara.shackleton@enron.com", "gerald.nemec@enron.com", "debra.perlingiere@enron.com",
  "vince.kaminski@enron.com", "tim.belden@enron.com", "greg.whalley@enron.com",
  "andrew.fastow@enron.com"
)

# Funzione per identificare se un'email è da/per VIP
identifica_vip <- function(from_email, to_emails, cc_emails = "", bcc_emails = "") {
  # Combina tutti gli indirizzi email dell'email
  tutti_indirizzi <- paste(from_email, to_emails, cc_emails, bcc_emails, sep = ";")
  tutti_indirizzi <- tolower(tutti_indirizzi)
  
  # Verifica se almeno un VIP è coinvolto
  any(sapply(vip_emails, function(vip) grepl(vip, tutti_indirizzi, fixed = TRUE)))
}

# Analisi del volume email mensile con contributo VIP
# Assumendo che 'final_emails' sia il tuo dataset
analisi_vip <- final_emails %>%
  mutate(
    date = as.Date(date_parsed),
    anno = year(date),
    mese = month(date),
    anno_mese = paste(anno, sprintf("%02d", mese), sep = "-")
  ) %>%
  filter(
    date >= as.Date("2001-01-01") & date <= as.Date("2001-12-31")
  ) %>%
  rowwise() %>%
  mutate(
    coinvolge_vip = identifica_vip(
      from_email = ifelse(!is.null(from), from, ""),
      to_emails  = ifelse(!is.null(to), to, ""),
      cc_emails  = if (has_cc) cc else "",
      bcc_emails = if (has_bcc) bcc else ""
    )
  ) %>%
  ungroup()

# Calcolo statistiche mensili
statistiche_mensili <- analisi_vip %>%
  group_by(anno_mese, mese) %>%
  summarise(
    totale_email = n(),
    email_vip = sum(coinvolge_vip, na.rm = TRUE),
    email_non_vip = totale_email - email_vip,
    percentuale_vip = round((email_vip / totale_email) * 100, 2),
    .groups = "drop"
  ) %>%
  arrange(anno_mese)

# Focus su ottobre-dicembre 2001
focus_ott_dic <- statistiche_mensili %>%
  filter(mese %in% c(10, 11, 12)) %>%
  mutate(
    mese_nome = case_when(
      mese == 10 ~ "Ottobre",
      mese == 11 ~ "Novembre", 
      mese == 12 ~ "Dicembre"
    )
  )

# Calcolo variazione percentuale del volume totale
focus_ott_dic <- focus_ott_dic %>%
  mutate(
    variazione_volume = case_when(
      mese == 10 ~ NA_real_,
      TRUE ~ round(((totale_email / lag(totale_email)) - 1) * 100, 1)
    )
  )

# Creazione tabella riassuntiva
print("=== ANALISI CONTRIBUTO VIP OTTOBRE-DICEMBRE 2001 ===")
print(focus_ott_dic %>% 
  select(mese_nome, totale_email, email_vip, email_non_vip, 
         percentuale_vip, variazione_volume))

# Calcolo del contributo VIP all'aumento del volume
print("\n=== DETTAGLIO CONTRIBUTO VIP ALL'AUMENTO ===")

for(i in 2:nrow(focus_ott_dic)) {
  mese_corrente <- focus_ott_dic$mese_nome[i]
  mese_precedente <- focus_ott_dic$mese_nome[i-1]
  
  # Aumento totale email
  aumento_totale <- focus_ott_dic$totale_email[i] - focus_ott_dic$totale_email[i-1]
  
  # Aumento email VIP
  aumento_vip <- focus_ott_dic$email_vip[i] - focus_ott_dic$email_vip[i-1]
  
  # Percentuale del contributo VIP all'aumento
  if(aumento_totale > 0) {
    contributo_vip_aumento <- round((aumento_vip / aumento_totale) * 100, 2)
    
    cat(sprintf("\nDa %s a %s:\n", mese_precedente, mese_corrente))
    cat(sprintf("- Aumento totale email: %d\n", aumento_totale))
    cat(sprintf("- Aumento email VIP: %d\n", aumento_vip))
    cat(sprintf("- Contributo VIP all'aumento: %.2f%%\n", contributo_vip_aumento))
    cat(sprintf("- Variazione volume totale: %.1f%%\n", focus_ott_dic$variazione_volume[i]))
  }
}

# Grafico visualizzazione
grafico_contributo <- focus_ott_dic %>%
  select(mese_nome, email_vip, email_non_vip) %>%
  pivot_longer(cols = c(email_vip, email_non_vip), 
               names_to = "tipo", values_to = "volume") %>%
  mutate(tipo = recode(tipo, 
                       "email_vip" = "Email VIP",
                       "email_non_vip" = "Email Non-VIP"))

ggplot(grafico_contributo, aes(x = mese_nome, y = volume, fill = tipo)) +
  geom_col(position = "stack") +
  geom_text(data = focus_ott_dic, 
            aes(x = mese_nome, y = totale_email, label = paste0(percentuale_vip, "%")),
            vjust = -0.5, color = "red", fontface = "bold", inherit.aes = FALSE) +
  labs(
    title = "Contributo VIP nel Volume Email (Ott-Dic 2001)",
    subtitle = "Percentuali rosse mostrano il contributo VIP sul totale",
    x = "Mese",
    y = "Numero Email",
    fill = "Tipo Email"
  ) +
  scale_fill_manual(values = c("Email VIP" = "#C00000", "Email Non-VIP" = "#7F7F7F")) +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = "#262626", color = NA),
    panel.background = element_rect(fill = "#262626", color = NA),
    text = element_text(color = "white"),
    axis.text = element_text(color = "white"),
    legend.text = element_text(color = "white"),
    legend.background = element_rect(fill = "#262626"),
    panel.grid = element_line(color = "#444444", size = 0.3)
  )

# Tabella finale formattata
tabella_finale <- focus_ott_dic %>%
  select(mese_nome, totale_email, email_vip, percentuale_vip, variazione_volume) %>%
  gt() %>%
  tab_header(title = "Contributo VIP Email Ottobre-Dicembre 2001") %>%
  cols_label(
    mese_nome = "Mese",
    totale_email = "Tot. Email",
    email_vip = "Email VIP",
    percentuale_vip = "% VIP",
    variazione_volume = "Var. Volume %"
  ) %>%
  fmt_number(columns = c(totale_email, email_vip), decimals = 0) %>%
  fmt_number(columns = percentuale_vip, decimals = 1, pattern = "{x}%") %>%
  fmt_number(columns = variazione_volume, decimals = 1, pattern = "{x}%") %>%
  tab_style(
    style = cell_text(color = "#C00000", weight = "bold"),
    locations = cells_body(columns = percentuale_vip)
  ) %>%
  tab_style(
    style = cell_text(color = "#2D9C5C", weight = "bold"),
    locations = cells_body(
      columns = variazione_volume,
      rows = !is.na(variazione_volume) & variazione_volume > 0
    )
  ) %>%
  tab_options(
    table.background.color = "#262626",
    table.font.color = "white"
  )

print(tabella_finale)


#Concluisoni: i VIP non hanno contribuito all'aumento del volume delle mail nei mesi di crisi.
```


#IN PIU' PER VEDERE L'ATTIVITà DI TUTTI GLI INDIRIZZI ASSOCIATI ALL ASTESSA PERSONA
```{r}

library(data.table)
library(stringr)

# Supponiamo che final_emails sia un data.table con colonne 'from' e 'to'

# 1. Trova tutti gli indirizzi email unici (from + to)
all_emails_addresses <- unique(c(final_emails$from, final_emails$to))

# 2. Trova gli indirizzi che contengono "kaminski"
kaminski_addresses <- all_emails_addresses[str_detect(all_emails_addresses, "fastow")]

cat("Indirizzi email di Kaminski trovati nel dataset:\n")
print(kaminski_addresses)

# 3. Filtra tutte le email inviate o ricevute da/verso questi indirizzi
kaminski_emails <- final_emails[
  from %in% kaminski_addresses | to %in% kaminski_addresses
]

cat("Email totali che coinvolgono Kaminski:", nrow(kaminski_emails), "\n")

# 4. Conta quante email ha inviato ciascun indirizzo Kaminski
sent_counts <- kaminski_emails[from %in% kaminski_addresses, .N, by = from]
setnames(sent_counts, c("from", "sent_count"))

# 5. Conta quante email ha ricevuto ciascun indirizzo Kaminski
received_counts <- kaminski_emails[to %in% kaminski_addresses, .N, by = to]
setnames(received_counts, c("to", "received_count"))

# 6. Unisci i conteggi inviate e ricevute
kaminski_email_counts <- merge(
  sent_counts, received_counts,
  by.x = "from", by.y = "to",
  all = TRUE
)

# 7. Rinomina colonna e sostituisci NA con 0
setnames(kaminski_email_counts, "from", "email")
kaminski_email_counts[is.na(sent_count), sent_count := 0]
kaminski_email_counts[is.na(received_count), received_count := 0]

# 8. Stampa il risultato finale
print(kaminski_email_counts)

```